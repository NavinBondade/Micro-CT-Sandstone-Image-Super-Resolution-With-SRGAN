{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libararies"
      ],
      "metadata": {
        "id": "NC_9UCIfYkqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMnhA3tS8aRr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL as Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "plt.style.use('ggplot')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing Dataset"
      ],
      "metadata": {
        "id": "SyCULijkY5Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "highres_images_dir = '/content/drive/MyDrive/Project/GANs/Sandstone_high_low_res/higres'\n",
        "lowres_images_dir = '/content/drive/MyDrive/Project/GANs/Sandstone_high_low_res/lowres'"
      ],
      "metadata": {
        "id": "BV0t0gjjaCu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(highres_images_dir, lowres_images_dir):\n",
        "  highres_images_path_list = [os.path.join(highres_images_dir, x) for x in sorted(os.listdir(highres_images_dir))]\n",
        "  lowres_images_path_list = [os.path.join(lowres_images_dir, x) for x in sorted(os.listdir(lowres_images_dir))]\n",
        "  return highres_images_path_list, lowres_images_path_list"
      ],
      "metadata": {
        "id": "NDcXzWQcjX-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highres_images_path_list, lowres_images_path_list = get_data(highres_images_dir, lowres_images_dir)"
      ],
      "metadata": {
        "id": "sVTXAAICjiAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(highres_images_path_list)\n",
        "print(f'Size of Dataset: ', len(highres_images_path_list))"
      ],
      "metadata": {
        "id": "jWIdIwfgmZlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lowres_images_path_list)\n",
        "print(f'Size of Dataset: ', len(highres_images_path_list))"
      ],
      "metadata": {
        "id": "wjzDXkLcmehr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Dataset"
      ],
      "metadata": {
        "id": "ofQht_ceY91a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image, title='', cmap = None):\n",
        "  plt.imshow(image, cmap=cmap, alpha=1)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "lZ9yKvxoRb4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowres_image = cv2.imread(lowres_images_path_list[5])\n",
        "show_image(lowres_image, 'Low Quality Image')"
      ],
      "metadata": {
        "id": "2zo2hpvYj3Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape Of Low Resolution Image:',lowres_image.shape)"
      ],
      "metadata": {
        "id": "xbt4M2VikUY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highres_image = cv2.imread(highres_images_path_list[5])\n",
        "show_image(highres_image, 'High Quality Image')"
      ],
      "metadata": {
        "id": "rRi1BKfJR3Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape Of High Resolution Image:',highres_image.shape)"
      ],
      "metadata": {
        "id": "xIEBPDUMqgC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_dataset(highres_images_path_list, lowres_images_path_list):\n",
        "  plt.figure(figsize=(10,9))\n",
        "  id = 0\n",
        "  for i in tqdm(range(12)):\n",
        "    plt.subplot(3,4,i+1)\n",
        "    if i%2==0:\n",
        "      highres_image_path = highres_images_path_list[id]\n",
        "      highres_image = cv2.imread(highres_image_path)\n",
        "      show_image(highres_image, cmap='gray')\n",
        "\n",
        "    elif i%2==1:\n",
        "      lowres_image_path = lowres_images_path_list[id]\n",
        "      lowres_image = cv2.imread(lowres_image_path)\n",
        "      show_image(lowres_image, cmap='gray')      \n",
        "      id = id + 1\n",
        "  plt.tight_layout()\n",
        "  plt.suptitle('Dataset', size=16)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FJDyiqKUR_2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_dataset(highres_images_path_list, lowres_images_path_list)"
      ],
      "metadata": {
        "id": "7fCaZezqFwCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Data"
      ],
      "metadata": {
        "id": "AJTdcS4-ZbCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data(lowres_images_path_list, highres_images_path_list):\n",
        "  X = np.zeros((len(lowres_images_path_list), 64, 64, 3), dtype=np.uint8).astype(np.float32)\n",
        "  y = np.zeros((len(highres_images_path_list), 256, 256, 3), dtype=np.uint8).astype(np.float32)\n",
        "\n",
        "  for i, (lowres_image_path, highres_image_path) in tqdm(enumerate(zip(lowres_images_path_list, highres_images_path_list))):\n",
        "    lowres_img = cv2.imread(lowres_image_path)\n",
        "    lowres_img = lowres_img/255.\n",
        "    X[i] = lowres_img\n",
        "\n",
        "    highres_img = cv2.imread(highres_image_path)\n",
        "    highres_img = highres_img/255.\n",
        "    y[i] = highres_img\n",
        "\n",
        "  return X, y  "
      ],
      "metadata": {
        "id": "IhBTOPj87xA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = build_data(lowres_images_path_list, highres_images_path_list)"
      ],
      "metadata": {
        "id": "i5CV71q48TkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input Data Shape & Size:',X.shape)"
      ],
      "metadata": {
        "id": "btGXhnx-r2sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input Data Shape & Size:',y.shape)"
      ],
      "metadata": {
        "id": "S916WJk6r9VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Dependencies"
      ],
      "metadata": {
        "id": "ryaJlvjHanLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
        "from tensorflow.keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "C7_1ObtOsq19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Attention U-Net Model"
      ],
      "metadata": {
        "id": "yw-aVnUSaroG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(ip):   \n",
        "  res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "  res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "  res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "  \n",
        "  res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "  res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "  \n",
        "  return add([ip,res_model])"
      ],
      "metadata": {
        "id": "q6S3ALdQSd1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upscale_block(ip): \n",
        "  up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "  up_model = UpSampling2D(size = 2 )(up_model)\n",
        "  up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "  \n",
        "  return up_model"
      ],
      "metadata": {
        "id": "1fUxwhx5TZg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generator(gen_ip, num_res_block):\n",
        "  layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "  layers = PReLU(shared_axes=[1,2])(layers)\n",
        "\n",
        "  temp = layers\n",
        "\n",
        "  for i in range(num_res_block):\n",
        "      layers = resnet_block(layers)\n",
        "\n",
        "  layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "  layers = BatchNormalization(momentum=0.5)(layers)\n",
        "  layers = add([layers,temp])\n",
        "\n",
        "  layers = upscale_block(layers)\n",
        "  layers = upscale_block(layers)\n",
        "\n",
        "  op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "\n",
        "  return Model(inputs=gen_ip, outputs=op, name='Generator')"
      ],
      "metadata": {
        "id": "Kmx_jrlETccF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "  disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "  \n",
        "  if bn:\n",
        "      disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "  \n",
        "  disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "  \n",
        "  return disc_model"
      ],
      "metadata": {
        "id": "7fJMapXpTgn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_discriminator(disc_ip):\n",
        "  df = 64\n",
        "  \n",
        "  d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "  d2 = discriminator_block(d1, df, strides=2)\n",
        "  d3 = discriminator_block(d2, df*2)\n",
        "  d4 = discriminator_block(d3, df*2, strides=2)\n",
        "  d5 = discriminator_block(d4, df*4)\n",
        "  d6 = discriminator_block(d5, df*4, strides=2)\n",
        "  d7 = discriminator_block(d6, df*8)\n",
        "  d8 = discriminator_block(d7, df*8, strides=2)\n",
        "\n",
        "  d8_5 = Flatten()(d8)\n",
        "  d9 = Dense(df*16)(d8_5)\n",
        "  d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "  validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "  return Model(disc_ip, validity, name='Discriminator')"
      ],
      "metadata": {
        "id": "3fbOqRNnTlQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg(hr_shape):\n",
        "  vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "  return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output, name='VGG19')"
      ],
      "metadata": {
        "id": "hkZSeR84TtpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "  gen_img = gen_model(lr_ip)\n",
        "  gen_features = vgg(gen_img)\n",
        "  disc_model.trainable = False\n",
        "  validity = disc_model(gen_img)\n",
        "  \n",
        "  return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features], name='Combine')"
      ],
      "metadata": {
        "id": "nxmduqOaTxG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spliting Dataset Into Train & Test"
      ],
      "metadata": {
        "id": "SsQurkasa0KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ionOXC7csgWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowres_train, lowres_test, highres_train, highres_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_UdTp4fAsDoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing Inputs"
      ],
      "metadata": {
        "id": "LBHKBMiia-oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "highres_shape = (highres_train.shape[1], highres_train.shape[2], highres_train.shape[3])\n",
        "lowres_shape = (lowres_train.shape[1], lowres_train.shape[2], lowres_train.shape[3])"
      ],
      "metadata": {
        "id": "DFIyB0tFsDlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lowres_ip = Input(shape=lowres_shape)\n",
        "highres_ip = Input(shape=highres_shape)"
      ],
      "metadata": {
        "id": "GJrybkwFuK6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiating Generator"
      ],
      "metadata": {
        "id": "r3kxrW_lbLO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = create_generator(lowres_ip, num_res_block = 16)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "hiCKQltlsDj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Generator"
      ],
      "metadata": {
        "id": "Av3Ri8wsbD-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(generator, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "metadata": {
        "id": "3_aKCrmyGkCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instantiating Discriminator"
      ],
      "metadata": {
        "id": "z506n5kAbdWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = create_discriminator(highres_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "oVSXRqc6sDiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Discriminator"
      ],
      "metadata": {
        "id": "Vwxqqiasbj29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(discriminator, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "metadata": {
        "id": "iCcGUAJD9eg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instantiating VGG19"
      ],
      "metadata": {
        "id": "U0PSvVc1bqUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = build_vgg((256,256,3))\n",
        "vgg.trainable = False\n",
        "print(vgg.summary())"
      ],
      "metadata": {
        "id": "j85JtAXGugpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing VGG19"
      ],
      "metadata": {
        "id": "iNi7HGhGbwIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(vgg, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "metadata": {
        "id": "dIPlP2mH9tdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Combine Model i.e Attention U-Net"
      ],
      "metadata": {
        "id": "Nd07u5WHb24i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan_model = create_comb(generator, discriminator, vgg, lowres_ip, highres_ip)\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "S089xK0fsDgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Combine Model i.e Attention U-Net"
      ],
      "metadata": {
        "id": "wZ7lfqQlb-3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(gan_model, show_shapes=True, show_layer_names=True, dpi=64)"
      ],
      "metadata": {
        "id": "t_G0gxmlGxGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compileing Model"
      ],
      "metadata": {
        "id": "j4_Y3PyOcFrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "d0yBIr3u1M4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing Batch"
      ],
      "metadata": {
        "id": "GYq3dKGicMcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1  \n",
        "train_lowres_batches = []\n",
        "train_highres_batches = []\n",
        "for it in range(int(highres_train.shape[0] / batch_size)):\n",
        "  start_idx = it * batch_size\n",
        "  end_idx = start_idx + batch_size\n",
        "  train_highres_batches.append(highres_train[start_idx:end_idx])\n",
        "  train_lowres_batches.append(lowres_train[start_idx:end_idx])"
      ],
      "metadata": {
        "id": "_qBhoJv1G7go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training The Model"
      ],
      "metadata": {
        "id": "iopbsnNGcY8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "per_epoch_g_losses = []\n",
        "per_epoch_d_losses = []\n",
        "\n",
        "for e in tqdm(range(epochs)):\n",
        "  fake_label = np.zeros((batch_size, 1)) \n",
        "  real_label = np.ones((batch_size,1)) \n",
        "  \n",
        "  g_losses = []\n",
        "  d_losses = []\n",
        "\n",
        "  for b in tqdm(range(len(train_highres_batches))):\n",
        "    lr_imgs = train_lowres_batches[b] \n",
        "    hr_imgs = train_highres_batches[b] \n",
        "    \n",
        "    fake_imgs = generator.predict_on_batch(lr_imgs) \n",
        "    \n",
        "    #First, train the discriminator on fake and real HR images. \n",
        "    discriminator.trainable = True\n",
        "    d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "    d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "    \n",
        "    #Now, train the generator by fixing discriminator as non-trainable\n",
        "    discriminator.trainable = False\n",
        "    \n",
        "    #Average the discriminator loss, just for reporting purposes. \n",
        "    d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
        "    \n",
        "    #Extract VGG features, to be used towards calculating loss\n",
        "    image_features = vgg.predict(hr_imgs)\n",
        "  \n",
        "    #Train the generator via GAN. \n",
        "    #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
        "    g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "    \n",
        "    #Save losses to a list so we can average and report. \n",
        "    d_losses.append(d_loss)\n",
        "    g_losses.append(g_loss)\n",
        "      \n",
        "  #Convert the list of losses to an array to make it easy to average    \n",
        "  g_losses = np.array(g_losses)\n",
        "  d_losses = np.array(d_losses)\n",
        "  \n",
        "  #Calculate the average losses for generator and discriminator\n",
        "  g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "  d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "\n",
        "  per_epoch_g_losses.append(g_loss)\n",
        "  per_epoch_d_losses.append(d_loss)\n",
        "  \n",
        "  #Report the progress during training. \n",
        "  print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "  if (e+1) % 10 == 0:\n",
        "    #Save the generator after every n epochs (Usually 10 epochs)\n",
        "    generator.save(\"gen_e_\"+ str(e+1) +\".h5\")"
      ],
      "metadata": {
        "id": "dpz8ZOOAHEko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generator Loss Visualization"
      ],
      "metadata": {
        "id": "_Y_CAbSOciJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.title(\"Generator Loss\")\n",
        "plt.plot(per_epoch_g_losses, \".:\", label=\"Loss\", linewidth=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gx0RUu7AlxHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_loss = []\n",
        "for value in tqdm(per_epoch_d_losses):\n",
        "  d_loss.append(np.sum(value) / len(value))"
      ],
      "metadata": {
        "id": "YRInXw0Fmkot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discriminator Loss Visualization"
      ],
      "metadata": {
        "id": "-Bk8btM_crVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.title(\"Discriminator Loss\")\n",
        "plt.plot(d_loss, \".:\", label=\"Loss\", linewidth=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "brMfVAqdl-ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention U-Net Prediction"
      ],
      "metadata": {
        "id": "xAVIGDGNc2pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint"
      ],
      "metadata": {
        "id": "C1On6ZraHGuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[X1, X2] = [lowres_test, highres_test]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "id = randint(0, len(X1), 1)\n",
        "n = 0\n",
        "pred_out = None\n",
        "for i in tqdm(range(12)):\n",
        "  plt.subplot(4,3,i+1)\n",
        "  \n",
        "  if n==0:\n",
        "    show_image((X1[id[0]] * 255).astype(np.uint8), title='Input Image')\n",
        "    \n",
        "    n+=1\n",
        "  elif n==1:\n",
        "    gen_image = generator.predict(X1[id])\n",
        "    show_image((gen_image[0] * 255).astype(np.uint8), title='SuperResolution Image')\n",
        "    \n",
        "    n+=1\n",
        "  elif n==2:\n",
        "    show_image((X2[id[0]] * 255).astype(np.uint8), title='Original Image')  \n",
        "    n=0\n",
        "    id = randint(0, len(X1), 1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8FavjPlrnoJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DU8hvh3oy8Ec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}